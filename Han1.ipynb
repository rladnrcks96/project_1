{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('home_out.csv', delimiter=\",\", dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[144  42   7   1   1]\n",
      " [121  41  10   1   1]\n",
      " [129  39   9   1   0]\n",
      " ...\n",
      " [117  37  10   1   2]\n",
      " [138  42   8   1   0]\n",
      " [103  43  14   1   0]]\n",
      "[48 44 41 ... 42 47 46]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = xy[0:,0:-1]\n",
    "print(X)\n",
    "Y = xy[0:,5:6]\n",
    "y = Y.ravel()\n",
    "print(y)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100,max_depth=2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features=4, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = clf.fit(X_train,y_train)\n",
    "RandomForestClassifier(bootstrap=True,class_weight=None,criterion='gini',max_depth=2, \n",
    "                       max_features=4, max_leaf_nodes=None,min_impurity_decrease=0.0,\n",
    "                       min_impurity_split=None,min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "                       oob_score=False, random_state=0, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00877584 0.54695354 0.03081167 0.32619752 0.08726143]\n",
      "[45 44 48 ... 43 48 47]\n",
      "[46, 45, 47, 44, 42, 47, 50, 41, 46, 44, 48, 44, 40, 46, 47, 45, 45, 43, 41, 43, 47, 47, 47, 48, 44, 45, 39, 46, 46, 46, 46, 49, 40, 47, 46, 45, 45, 43, 45, 46, 45, 49, 45, 46, 41, 49, 45, 44, 41, 45, 44, 45, 44, 45, 45, 47, 51, 48, 47, 45, 41, 43, 43, 45, 48, 45, 49, 44, 45, 44, 44, 40, 47, 41, 43, 43, 44, 46, 45, 42, 44, 43, 46, 44, 40, 45, 49, 47, 42, 47, 45, 48, 41, 45, 43, 49, 45, 47, 43, 43, 44, 46, 41, 49, 50, 44, 44, 50, 41, 46, 45, 43, 42, 40, 43, 47, 46, 42, 46, 50, 48, 46, 48, 48, 46, 43, 46, 49, 48, 46, 49, 46, 42, 43, 42, 42, 46, 47, 45, 47, 44, 46, 42, 38, 47, 48, 45, 43, 44, 45, 45, 44, 48, 43, 44, 45, 40, 42, 44, 44, 45, 48, 44, 48, 46, 46, 44, 45, 46, 42, 48, 45, 39, 51, 47, 45, 47, 44, 46, 40, 42, 44, 44, 45, 49, 45, 44, 44, 45, 46, 42, 46, 47, 42, 44, 43, 49, 46, 46, 41, 45, 49, 43, 45, 49, 42, 43, 47, 48, 44, 39, 46, 43, 44, 49, 47, 40, 44, 47, 42, 48, 44, 41, 44, 46, 41, 47, 47, 41, 43, 49, 46, 45, 42, 42, 46, 43, 45, 46, 48, 42, 43, 45, 49, 45, 39, 41, 46, 47, 47, 46, 41, 47, 42, 46, 46, 45, 43, 40, 43, 43, 45, 43, 47, 46, 48, 45, 48, 46, 43, 45, 47, 46, 43, 46, 48, 44, 43, 44, 43, 44, 45, 43, 47, 46, 42, 44, 41, 47, 47, 47, 46, 43, 45, 44, 48, 47, 44, 43, 44, 47, 49, 38, 45, 38, 47, 50, 48, 44, 48, 45, 45, 37, 48, 46, 46, 45, 47, 46, 46, 47, 47, 46, 42, 48, 44, 46, 44, 45, 48, 46, 47, 47, 45, 48, 46, 47, 47, 49, 42, 44, 44, 47, 46, 46, 42, 44, 43, 46, 43, 47, 45, 42, 44, 47, 42, 48, 45, 46, 48, 44, 48, 43, 45, 43, 42, 48, 44, 50, 48, 48, 41, 46, 47, 45, 48, 47, 43, 45, 45, 50, 47, 47, 52, 42, 46, 45, 46, 47, 43, 47, 47, 44, 44, 43, 47, 49, 42, 46, 44, 48, 42, 46, 43, 48, 37, 45, 49, 42, 44, 45, 47, 48, 48, 46, 45, 46, 44, 46, 45, 44, 42, 45, 46, 50, 50, 44, 42, 47, 45, 47, 44, 48, 48, 44, 45, 40, 50, 45, 50, 42, 47, 46, 48, 42, 44, 41, 47, 48, 48, 43, 47, 45, 44, 43, 47, 47, 44, 41, 51, 41, 44, 43, 42, 44, 47, 47, 49, 43, 50, 46, 43, 43, 42, 50, 47, 44, 43, 49, 43, 48, 44, 50, 43, 44, 46, 44, 45, 47, 45, 45, 45, 41, 46, 49, 46, 45, 45, 44, 47, 48, 44, 52, 49, 46, 43, 47, 41, 39, 43, 48, 46, 47, 40, 43, 46, 44, 47, 48, 42, 42, 48, 47, 45, 46, 47, 47, 45, 47, 46, 46, 48, 45, 43, 48, 48, 46, 45, 42, 47, 45, 39, 48, 43, 47, 54, 40, 48, 48, 46, 43, 48, 48, 47, 44, 45, 47, 47, 43, 40, 45, 47, 46, 49, 47, 46, 45, 47, 45, 44, 48, 41, 44, 46, 45, 48, 48, 48, 49, 44, 47, 48, 46, 42, 45, 44, 44, 42, 43, 48, 44, 43, 46, 45, 46, 48, 44, 48, 43, 44, 42, 44, 48, 42, 39, 45, 50, 48, 41, 47, 47, 45, 45, 43, 49, 42, 45, 43, 42, 42, 42, 44, 44, 52, 44, 44, 46, 48, 48, 40, 46, 46, 48, 46, 44, 45, 47, 45, 49, 44, 51, 46, 47, 46, 44, 45, 48, 41, 45, 43, 43, 44, 45, 43, 42, 43, 47, 45, 43, 44, 45, 46, 39, 43, 49, 46, 45, 46, 46, 49, 45, 43, 49, 44, 46, 46, 42, 46, 40, 47, 49, 43, 46, 40, 41, 41, 46, 42, 46, 46, 44, 47, 46, 45, 49, 49, 50, 47, 43, 45, 46, 49, 47, 40, 43, 47, 45, 43, 45, 46, 44, 43, 48, 49, 41, 45, 45, 46, 45, 45, 46, 44, 46, 42, 44, 49, 42, 43, 46, 50, 45, 46, 40, 45, 45, 45, 43, 48, 42, 48, 46, 42, 41, 39, 45, 44, 44, 52, 49, 44, 47, 46, 46, 48, 42, 47, 47, 50, 49, 45, 46, 38, 43, 43, 42, 48, 46, 47, 50, 42, 44, 43, 46, 44, 47, 46, 43, 43, 47, 45, 47, 46, 48, 45, 47, 45, 45, 43, 43, 45, 43, 47, 46, 43, 45, 43, 43, 44, 44, 46, 44, 46, 44, 43, 48, 45, 43, 47, 49, 46, 44, 46, 39, 46, 49, 51, 39, 44, 45, 43, 45, 48, 48, 42, 45, 41, 43, 43, 49, 45, 46, 43, 50, 47, 45, 43, 46, 48, 48, 44, 43, 48, 45, 42, 41, 43, 50, 39, 46, 49, 47, 43, 42, 46, 42, 47, 44, 43, 46, 46, 42, 40, 45, 48, 42, 42, 44, 47, 46, 47, 52, 45, 44, 43, 47, 47, 44, 43, 43, 43, 49, 46, 46, 49, 48, 43, 45, 43, 45, 43, 44, 44, 44, 47, 44, 50, 45, 44, 42, 46, 47, 45, 47, 45, 49, 53, 49, 42, 40, 44, 46, 47, 49, 43, 42, 46, 40, 47, 49, 45, 45, 41, 44, 47, 45, 48, 44, 43, 48, 48, 48, 44, 49, 47, 47, 49, 45, 46, 47, 43, 45, 47, 49, 45, 46, 44, 44, 50, 43, 42, 45, 48, 42, 45, 45, 50, 48, 48, 51, 48, 44, 46, 47, 43, 46, 49, 48, 46, 45, 45, 45, 49, 44, 46, 44, 44, 45, 45, 44, 51, 44, 44, 46, 42, 44, 40, 46, 46, 44, 48, 43, 48, 39, 47, 45, 47, 47, 46, 45, 44, 48, 43, 47, 49, 47, 47, 46, 48, 43, 43, 45, 48, 44, 50, 41, 41, 48, 45, 43, 46, 40, 45, 46, 46, 44, 45, 46, 42, 42, 48, 43, 44, 45, 46, 45, 44, 42, 40, 49, 47, 46, 46, 44, 47, 45, 46, 47, 47, 47, 45, 48, 47, 50, 44, 38, 51, 44, 41, 50, 48, 51, 46, 48, 42, 42, 50, 48, 46, 41, 43, 46, 44, 45, 48, 44, 47, 43, 44, 41, 44, 44, 46, 45, 51, 47, 46, 47, 49, 46, 44, 46, 41, 46, 50, 47, 43, 49, 47, 45, 51, 46, 46, 47, 44, 49, 47, 44, 41, 42, 51, 47, 47, 44, 43, 48, 45, 46, 44, 43, 45, 46, 48, 47, 45, 44, 48, 42, 45, 44, 46, 43, 46, 46, 46, 48, 48, 49, 46, 44, 44, 47, 43, 43, 49, 43, 44, 44, 43, 45, 46, 43, 50, 43, 41, 45, 42, 43, 46, 47, 39, 44, 47, 48, 47, 43, 46, 46, 45, 48, 43, 48, 47, 42, 47, 46, 49, 42, 45, 45, 43, 44, 44, 45, 48, 44, 47, 44, 41, 49, 45, 48, 42, 39, 44, 51, 45, 44, 42, 44, 46, 44, 41, 46, 44, 44, 48, 43, 47, 49, 44, 46, 46, 44, 47, 46, 51, 50, 42, 44, 43, 47, 49, 43, 49, 48, 45, 44, 47, 42, 48, 45, 46, 43, 46, 42, 43, 50, 41, 45, 47, 47, 42, 48, 44, 47, 46, 49, 46, 47, 46, 46, 42, 44, 45, 44, 44, 45, 46, 42, 44, 48, 44, 46, 47, 44, 50, 42, 45, 46, 46, 47, 48, 48, 50, 46, 45, 46, 46, 40, 43, 45, 47, 46, 46, 41, 51, 46, 48, 45, 45, 44, 44, 44, 42, 50, 43, 48, 48, 50, 45, 40, 41, 43, 47, 42, 43, 40, 43, 49, 44, 46, 48, 49, 43, 46, 41, 39, 46, 45, 48, 43, 44, 43, 43, 44, 48, 43, 43, 45, 46, 47, 46, 43, 45, 47, 48, 44, 40, 47, 43, 46, 45, 48, 45, 43, 48, 45, 45, 45, 45, 43, 46, 43, 52, 44, 48, 49, 45, 44, 46, 50, 45, 48, 40, 45, 45, 46, 46, 43, 49, 47, 45, 47, 43, 45, 45, 49, 49, 48, 47, 44, 47, 46, 45, 44, 47, 45, 43, 46, 47, 41, 50, 44, 39, 42, 47, 47, 43, 48, 47, 50, 41, 46, 47, 44, 45, 44, 45, 42, 49, 47, 47, 45, 44, 45, 46, 45, 49, 48, 45, 46, 45, 43, 46, 47, 47, 50, 45, 43, 44, 44, 42, 44, 45, 42, 40, 44, 44, 47, 46, 39, 47, 48, 41, 42, 45, 46, 49, 42, 40, 39, 43, 47, 43, 47, 43, 45, 41, 42, 48, 41, 45, 46, 48, 46, 46, 49, 44, 43, 45, 49, 48, 41, 47, 45, 47, 45, 44, 48, 43, 42, 47, 45, 47, 48, 45, 47, 44, 46, 45, 44, 46, 46, 48, 45, 44, 42, 46, 48, 45, 45, 47, 45, 45, 47, 47, 47, 48, 41, 45, 42, 44, 44, 46, 43, 43, 41, 44, 46, 38, 49, 43, 43, 43, 41, 50, 52, 50, 46, 45, 44, 43, 50, 49, 49, 43, 42, 41, 44, 43, 42, 47, 45, 44, 42, 47, 43, 45, 48, 45, 46, 47, 45, 41, 46, 42, 47, 46, 48, 42, 45, 46, 47, 46, 48, 47, 49, 44, 43, 43, 49, 50, 45, 43, 43, 47, 50, 47, 46, 47, 37, 51, 46, 44, 46, 47, 40, 45, 45, 42, 45, 43, 48, 48, 44, 45, 50, 47, 47, 46, 47, 44, 43, 46, 50, 43, 50, 46, 41, 43, 42, 45, 42, 44, 44, 46, 40, 45, 41, 47, 46, 46, 40, 46, 44, 45, 47, 48, 46, 48, 45, 46, 52, 44, 40, 49, 51, 47, 48, 43, 46, 41, 43, 50, 43, 52, 47, 44, 45, 46, 45, 47, 47, 48, 48, 49, 44, 50, 37, 49, 44, 41, 47, 45, 43, 46, 45, 50, 44, 49, 44, 48, 45, 39, 47, 41, 49, 46, 39, 46, 43, 46, 43, 44, 41, 44, 48, 42, 46, 44, 46, 45, 45, 47, 42, 47, 44, 43, 47, 39, 43, 45, 46, 45, 43, 48, 46, 41, 42, 40, 45, 44, 43, 50, 45, 43, 50, 46, 47, 41, 45, 46, 45, 47, 43, 45, 43, 44, 41, 38, 42, 45, 46, 44, 45, 41, 42, 52, 47, 40, 43, 44, 45, 45, 45, 45, 42, 47, 41, 45, 45, 47, 45, 49, 41, 48, 46, 49, 47, 42, 41, 45, 42, 45, 46, 44, 47, 47, 42, 46, 49, 39, 45, 43, 50, 46, 47, 48, 46, 44, 46, 40, 48, 48, 44, 46, 42, 47, 45, 44, 45, 45, 43, 48, 50, 44, 46, 45, 45, 47, 42, 43, 47, 41, 40, 44, 45, 46, 42, 50, 41, 44, 41, 42, 49, 43, 41, 48, 46, 41, 49, 43, 49, 48, 47, 46, 44, 46, 43, 42, 41, 45, 43, 46, 43, 46, 46, 45, 48, 47, 47, 48, 46, 40, 49, 47, 46, 42, 47, 43, 44, 48, 44, 46, 46, 43, 40, 46, 43, 46, 44, 47, 48, 46, 48, 46, 43, 48, 45, 45, 43, 39, 42, 46, 45, 45, 49, 44, 45, 44, 48, 46, 42, 49, 41, 48, 45, 40, 49, 45, 43, 45, 45, 49, 44, 42, 46, 43, 49, 46, 45, 49, 43, 43, 44, 40, 45, 48, 46, 47, 45, 44, 43, 44, 47, 45, 43, 44, 43, 45, 47, 47, 43, 45, 46, 46, 43, 41, 47, 45, 49, 45, 42, 41, 43, 46, 47, 41, 48, 45, 43, 43, 44, 43, 46, 45, 48, 38, 45, 48, 48, 42, 46, 47, 39, 42, 48, 47, 48, 42, 48, 41, 46, 43, 47, 49, 43, 47, 47, 43, 41, 44, 43, 43, 44, 48, 50, 42, 47, 48, 38, 48, 48, 47, 41, 43, 46, 44, 47, 42, 45, 44, 44, 50, 48, 46, 42, 38, 46, 46]\n"
     ]
    }
   ],
   "source": [
    "print(clf.feature_importances_)\n",
    "predict = clf.predict(X_test)\n",
    "print(predict)\n",
    "print(list(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.2255\n"
     ]
    }
   ],
   "source": [
    " print('정확도 :', metrics.accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 0\n",
    "score3 = 0\n",
    "\n",
    "\n",
    "while number < 1999:\n",
    "    if predict[number] >= y_test[number] - 3 and predict[number] <= y_test[number] + 3:\n",
    "        score3 = score3 + 1\n",
    "    number = number + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 0\n",
    "score2 = 0\n",
    "\n",
    "\n",
    "while number < 1999:\n",
    "    if predict[number] >= y_test[number] - 2 and predict[number] <= y_test[number] + 2:\n",
    "        score2 = score2 + 1\n",
    "    number = number + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 0\n",
    "score1 = 0\n",
    "\n",
    "\n",
    "while number < 1999:\n",
    "    if predict[number] >= y_test[number] - 1 and predict[number] <= y_test[number] + 1:\n",
    "        score1 = score1 + 1\n",
    "    number = number + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954\n",
      "0.857\n",
      "0.619\n"
     ]
    }
   ],
   "source": [
    "print(score3/2000)\n",
    "print(score2/2000)\n",
    "print(score1/2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
